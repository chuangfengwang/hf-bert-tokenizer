#
# Autogenerated by Thrift Compiler (0.19.0)
#
# DO NOT EDIT UNLESS YOU ARE SURE THAT YOU KNOW WHAT YOU ARE DOING
#
#  options string: py
#

from thrift.Thrift import TType, TMessageType, TFrozenDict, TException, TApplicationException
from thrift.protocol.TProtocol import TProtocolException
from thrift.TRecursive import fix_spec

import sys

from thrift.transport import TTransport
all_structs = []


class BaseResponse(object):
    """
    Attributes:
     - status
     - msg
     - in_time

    """


    def __init__(self, status=0, msg="", in_time=0.0000000000000000,):
        self.status = status
        self.msg = msg
        self.in_time = in_time

    def read(self, iprot):
        if iprot._fast_decode is not None and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None:
            iprot._fast_decode(self, iprot, [self.__class__, self.thrift_spec])
            return
        iprot.readStructBegin()
        while True:
            (fname, ftype, fid) = iprot.readFieldBegin()
            if ftype == TType.STOP:
                break
            if fid == 1:
                if ftype == TType.I32:
                    self.status = iprot.readI32()
                else:
                    iprot.skip(ftype)
            elif fid == 2:
                if ftype == TType.STRING:
                    self.msg = iprot.readString().decode('utf-8', errors='replace') if sys.version_info[0] == 2 else iprot.readString()
                else:
                    iprot.skip(ftype)
            elif fid == 3:
                if ftype == TType.DOUBLE:
                    self.in_time = iprot.readDouble()
                else:
                    iprot.skip(ftype)
            else:
                iprot.skip(ftype)
            iprot.readFieldEnd()
        iprot.readStructEnd()

    def write(self, oprot):
        if oprot._fast_encode is not None and self.thrift_spec is not None:
            oprot.trans.write(oprot._fast_encode(self, [self.__class__, self.thrift_spec]))
            return
        oprot.writeStructBegin('BaseResponse')
        if self.status is not None:
            oprot.writeFieldBegin('status', TType.I32, 1)
            oprot.writeI32(self.status)
            oprot.writeFieldEnd()
        if self.msg is not None:
            oprot.writeFieldBegin('msg', TType.STRING, 2)
            oprot.writeString(self.msg.encode('utf-8') if sys.version_info[0] == 2 else self.msg)
            oprot.writeFieldEnd()
        if self.in_time is not None:
            oprot.writeFieldBegin('in_time', TType.DOUBLE, 3)
            oprot.writeDouble(self.in_time)
            oprot.writeFieldEnd()
        oprot.writeFieldStop()
        oprot.writeStructEnd()

    def validate(self):
        if self.status is None:
            raise TProtocolException(message='Required field status is unset!')
        return

    def __repr__(self):
        L = ['%s=%r' % (key, value)
             for key, value in self.__dict__.items()]
        return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

    def __eq__(self, other):
        return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

    def __ne__(self, other):
        return not (self == other)


class TokenizerParam(object):
    """
    Attributes:
     - text_list
     - wrapper_id

    """


    def __init__(self, text_list=None, wrapper_id=False,):
        self.text_list = text_list
        self.wrapper_id = wrapper_id

    def read(self, iprot):
        if iprot._fast_decode is not None and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None:
            iprot._fast_decode(self, iprot, [self.__class__, self.thrift_spec])
            return
        iprot.readStructBegin()
        while True:
            (fname, ftype, fid) = iprot.readFieldBegin()
            if ftype == TType.STOP:
                break
            if fid == 1:
                if ftype == TType.LIST:
                    self.text_list = []
                    (_etype3, _size0) = iprot.readListBegin()
                    for _i4 in range(_size0):
                        _elem5 = iprot.readString().decode('utf-8', errors='replace') if sys.version_info[0] == 2 else iprot.readString()
                        self.text_list.append(_elem5)
                    iprot.readListEnd()
                else:
                    iprot.skip(ftype)
            elif fid == 2:
                if ftype == TType.BOOL:
                    self.wrapper_id = iprot.readBool()
                else:
                    iprot.skip(ftype)
            else:
                iprot.skip(ftype)
            iprot.readFieldEnd()
        iprot.readStructEnd()

    def write(self, oprot):
        if oprot._fast_encode is not None and self.thrift_spec is not None:
            oprot.trans.write(oprot._fast_encode(self, [self.__class__, self.thrift_spec]))
            return
        oprot.writeStructBegin('TokenizerParam')
        if self.text_list is not None:
            oprot.writeFieldBegin('text_list', TType.LIST, 1)
            oprot.writeListBegin(TType.STRING, len(self.text_list))
            for iter6 in self.text_list:
                oprot.writeString(iter6.encode('utf-8') if sys.version_info[0] == 2 else iter6)
            oprot.writeListEnd()
            oprot.writeFieldEnd()
        if self.wrapper_id is not None:
            oprot.writeFieldBegin('wrapper_id', TType.BOOL, 2)
            oprot.writeBool(self.wrapper_id)
            oprot.writeFieldEnd()
        oprot.writeFieldStop()
        oprot.writeStructEnd()

    def validate(self):
        if self.text_list is None:
            raise TProtocolException(message='Required field text_list is unset!')
        return

    def __repr__(self):
        L = ['%s=%r' % (key, value)
             for key, value in self.__dict__.items()]
        return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

    def __eq__(self, other):
        return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

    def __ne__(self, other):
        return not (self == other)


class TokenizerResult(object):
    """
    Attributes:
     - tokenizer_word_list
     - tokenizer_id_list
     - base

    """


    def __init__(self, tokenizer_word_list=None, tokenizer_id_list=None, base=None,):
        self.tokenizer_word_list = tokenizer_word_list
        self.tokenizer_id_list = tokenizer_id_list
        self.base = base

    def read(self, iprot):
        if iprot._fast_decode is not None and isinstance(iprot.trans, TTransport.CReadableTransport) and self.thrift_spec is not None:
            iprot._fast_decode(self, iprot, [self.__class__, self.thrift_spec])
            return
        iprot.readStructBegin()
        while True:
            (fname, ftype, fid) = iprot.readFieldBegin()
            if ftype == TType.STOP:
                break
            if fid == 1:
                if ftype == TType.LIST:
                    self.tokenizer_word_list = []
                    (_etype10, _size7) = iprot.readListBegin()
                    for _i11 in range(_size7):
                        _elem12 = []
                        (_etype16, _size13) = iprot.readListBegin()
                        for _i17 in range(_size13):
                            _elem18 = iprot.readString().decode('utf-8', errors='replace') if sys.version_info[0] == 2 else iprot.readString()
                            _elem12.append(_elem18)
                        iprot.readListEnd()
                        self.tokenizer_word_list.append(_elem12)
                    iprot.readListEnd()
                else:
                    iprot.skip(ftype)
            elif fid == 2:
                if ftype == TType.LIST:
                    self.tokenizer_id_list = []
                    (_etype22, _size19) = iprot.readListBegin()
                    for _i23 in range(_size19):
                        _elem24 = []
                        (_etype28, _size25) = iprot.readListBegin()
                        for _i29 in range(_size25):
                            _elem30 = iprot.readI32()
                            _elem24.append(_elem30)
                        iprot.readListEnd()
                        self.tokenizer_id_list.append(_elem24)
                    iprot.readListEnd()
                else:
                    iprot.skip(ftype)
            elif fid == 255:
                if ftype == TType.STRUCT:
                    self.base = BaseResponse()
                    self.base.read(iprot)
                else:
                    iprot.skip(ftype)
            else:
                iprot.skip(ftype)
            iprot.readFieldEnd()
        iprot.readStructEnd()

    def write(self, oprot):
        if oprot._fast_encode is not None and self.thrift_spec is not None:
            oprot.trans.write(oprot._fast_encode(self, [self.__class__, self.thrift_spec]))
            return
        oprot.writeStructBegin('TokenizerResult')
        if self.tokenizer_word_list is not None:
            oprot.writeFieldBegin('tokenizer_word_list', TType.LIST, 1)
            oprot.writeListBegin(TType.LIST, len(self.tokenizer_word_list))
            for iter31 in self.tokenizer_word_list:
                oprot.writeListBegin(TType.STRING, len(iter31))
                for iter32 in iter31:
                    oprot.writeString(iter32.encode('utf-8') if sys.version_info[0] == 2 else iter32)
                oprot.writeListEnd()
            oprot.writeListEnd()
            oprot.writeFieldEnd()
        if self.tokenizer_id_list is not None:
            oprot.writeFieldBegin('tokenizer_id_list', TType.LIST, 2)
            oprot.writeListBegin(TType.LIST, len(self.tokenizer_id_list))
            for iter33 in self.tokenizer_id_list:
                oprot.writeListBegin(TType.I32, len(iter33))
                for iter34 in iter33:
                    oprot.writeI32(iter34)
                oprot.writeListEnd()
            oprot.writeListEnd()
            oprot.writeFieldEnd()
        if self.base is not None:
            oprot.writeFieldBegin('base', TType.STRUCT, 255)
            self.base.write(oprot)
            oprot.writeFieldEnd()
        oprot.writeFieldStop()
        oprot.writeStructEnd()

    def validate(self):
        if self.tokenizer_word_list is None:
            raise TProtocolException(message='Required field tokenizer_word_list is unset!')
        return

    def __repr__(self):
        L = ['%s=%r' % (key, value)
             for key, value in self.__dict__.items()]
        return '%s(%s)' % (self.__class__.__name__, ', '.join(L))

    def __eq__(self, other):
        return isinstance(other, self.__class__) and self.__dict__ == other.__dict__

    def __ne__(self, other):
        return not (self == other)
all_structs.append(BaseResponse)
BaseResponse.thrift_spec = (
    None,  # 0
    (1, TType.I32, 'status', None, 0, ),  # 1
    (2, TType.STRING, 'msg', 'UTF8', "", ),  # 2
    (3, TType.DOUBLE, 'in_time', None, 0.0000000000000000, ),  # 3
)
all_structs.append(TokenizerParam)
TokenizerParam.thrift_spec = (
    None,  # 0
    (1, TType.LIST, 'text_list', (TType.STRING, 'UTF8', False), None, ),  # 1
    (2, TType.BOOL, 'wrapper_id', None, False, ),  # 2
)
all_structs.append(TokenizerResult)
TokenizerResult.thrift_spec = (
    None,  # 0
    (1, TType.LIST, 'tokenizer_word_list', (TType.LIST, (TType.STRING, 'UTF8', False), False), None, ),  # 1
    (2, TType.LIST, 'tokenizer_id_list', (TType.LIST, (TType.I32, None, False), False), None, ),  # 2
    None,  # 3
    None,  # 4
    None,  # 5
    None,  # 6
    None,  # 7
    None,  # 8
    None,  # 9
    None,  # 10
    None,  # 11
    None,  # 12
    None,  # 13
    None,  # 14
    None,  # 15
    None,  # 16
    None,  # 17
    None,  # 18
    None,  # 19
    None,  # 20
    None,  # 21
    None,  # 22
    None,  # 23
    None,  # 24
    None,  # 25
    None,  # 26
    None,  # 27
    None,  # 28
    None,  # 29
    None,  # 30
    None,  # 31
    None,  # 32
    None,  # 33
    None,  # 34
    None,  # 35
    None,  # 36
    None,  # 37
    None,  # 38
    None,  # 39
    None,  # 40
    None,  # 41
    None,  # 42
    None,  # 43
    None,  # 44
    None,  # 45
    None,  # 46
    None,  # 47
    None,  # 48
    None,  # 49
    None,  # 50
    None,  # 51
    None,  # 52
    None,  # 53
    None,  # 54
    None,  # 55
    None,  # 56
    None,  # 57
    None,  # 58
    None,  # 59
    None,  # 60
    None,  # 61
    None,  # 62
    None,  # 63
    None,  # 64
    None,  # 65
    None,  # 66
    None,  # 67
    None,  # 68
    None,  # 69
    None,  # 70
    None,  # 71
    None,  # 72
    None,  # 73
    None,  # 74
    None,  # 75
    None,  # 76
    None,  # 77
    None,  # 78
    None,  # 79
    None,  # 80
    None,  # 81
    None,  # 82
    None,  # 83
    None,  # 84
    None,  # 85
    None,  # 86
    None,  # 87
    None,  # 88
    None,  # 89
    None,  # 90
    None,  # 91
    None,  # 92
    None,  # 93
    None,  # 94
    None,  # 95
    None,  # 96
    None,  # 97
    None,  # 98
    None,  # 99
    None,  # 100
    None,  # 101
    None,  # 102
    None,  # 103
    None,  # 104
    None,  # 105
    None,  # 106
    None,  # 107
    None,  # 108
    None,  # 109
    None,  # 110
    None,  # 111
    None,  # 112
    None,  # 113
    None,  # 114
    None,  # 115
    None,  # 116
    None,  # 117
    None,  # 118
    None,  # 119
    None,  # 120
    None,  # 121
    None,  # 122
    None,  # 123
    None,  # 124
    None,  # 125
    None,  # 126
    None,  # 127
    None,  # 128
    None,  # 129
    None,  # 130
    None,  # 131
    None,  # 132
    None,  # 133
    None,  # 134
    None,  # 135
    None,  # 136
    None,  # 137
    None,  # 138
    None,  # 139
    None,  # 140
    None,  # 141
    None,  # 142
    None,  # 143
    None,  # 144
    None,  # 145
    None,  # 146
    None,  # 147
    None,  # 148
    None,  # 149
    None,  # 150
    None,  # 151
    None,  # 152
    None,  # 153
    None,  # 154
    None,  # 155
    None,  # 156
    None,  # 157
    None,  # 158
    None,  # 159
    None,  # 160
    None,  # 161
    None,  # 162
    None,  # 163
    None,  # 164
    None,  # 165
    None,  # 166
    None,  # 167
    None,  # 168
    None,  # 169
    None,  # 170
    None,  # 171
    None,  # 172
    None,  # 173
    None,  # 174
    None,  # 175
    None,  # 176
    None,  # 177
    None,  # 178
    None,  # 179
    None,  # 180
    None,  # 181
    None,  # 182
    None,  # 183
    None,  # 184
    None,  # 185
    None,  # 186
    None,  # 187
    None,  # 188
    None,  # 189
    None,  # 190
    None,  # 191
    None,  # 192
    None,  # 193
    None,  # 194
    None,  # 195
    None,  # 196
    None,  # 197
    None,  # 198
    None,  # 199
    None,  # 200
    None,  # 201
    None,  # 202
    None,  # 203
    None,  # 204
    None,  # 205
    None,  # 206
    None,  # 207
    None,  # 208
    None,  # 209
    None,  # 210
    None,  # 211
    None,  # 212
    None,  # 213
    None,  # 214
    None,  # 215
    None,  # 216
    None,  # 217
    None,  # 218
    None,  # 219
    None,  # 220
    None,  # 221
    None,  # 222
    None,  # 223
    None,  # 224
    None,  # 225
    None,  # 226
    None,  # 227
    None,  # 228
    None,  # 229
    None,  # 230
    None,  # 231
    None,  # 232
    None,  # 233
    None,  # 234
    None,  # 235
    None,  # 236
    None,  # 237
    None,  # 238
    None,  # 239
    None,  # 240
    None,  # 241
    None,  # 242
    None,  # 243
    None,  # 244
    None,  # 245
    None,  # 246
    None,  # 247
    None,  # 248
    None,  # 249
    None,  # 250
    None,  # 251
    None,  # 252
    None,  # 253
    None,  # 254
    (255, TType.STRUCT, 'base', [BaseResponse, None], None, ),  # 255
)
fix_spec(all_structs)
del all_structs
